{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "def build_model(num_classes):\n",
    "    # construct CNN structure\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(2, 2)))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # fully connected neural networks\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n",
      "instance length:  2304\n",
      "28709 train samples\n",
      "3589 test samples\n",
      "--------x_train.shape: (28709, 48, 48, 1)\n",
      "--------y_train.shape: (28709, 7)\n",
      "28709 train x size\n",
      "28709 train y size\n",
      "3589 test x size\n",
      "3589 test y size\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "model: <keras.engine.sequential.Sequential object at 0x0000022358F0DF88>\n",
      "train_generator: <keras.preprocessing.image.NumpyArrayIterator object at 0x000002234E1DD788>\n",
      "m: <keras.engine.sequential.Sequential object at 0x0000022358F0DF88>\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "256/256 [==============================] - 398s 2s/step - loss: 1.7682 - accuracy: 0.2705\n",
      "Epoch 2/5\n",
      "256/256 [==============================] - 401s 2s/step - loss: 1.5586 - accuracy: 0.3875\n",
      "Epoch 3/5\n",
      "256/256 [==============================] - 400s 2s/step - loss: 1.3887 - accuracy: 0.4678\n",
      "Epoch 4/5\n",
      "256/256 [==============================] - 416s 2s/step - loss: 1.2902 - accuracy: 0.5072\n",
      "Epoch 5/5\n",
      "256/256 [==============================] - 428s 2s/step - loss: 1.2159 - accuracy: 0.5371\n",
      "save weight..\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from model import build_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_data_np(path):\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    lines = np.array(content)\n",
    "\n",
    "    num_of_instances = lines.size\n",
    "    print(\"number of instances: \", num_of_instances)\n",
    "    print(\"instance length: \", len(lines[1].split(\",\")[1].split(\" \")))\n",
    "\n",
    "    return lines, num_of_instances\n",
    "\n",
    "\n",
    "def read_data_pd(path):\n",
    "\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    lines = len(data_df)\n",
    "    print(data_df.head())\n",
    "\n",
    "    return data_df, lines\n",
    "\n",
    "\n",
    "def reshape_dataset(paths, num_classes):\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "    lines, num_of_instances = read_data_np(paths)\n",
    "    # data_df, lines = read_data_pd(paths)\n",
    "\n",
    "    # ------------------------------\n",
    "    # transfer train and test set data\n",
    "    for i in range(1, num_of_instances):\n",
    "        try:\n",
    "            emotion, img, usage = lines[i].split(\",\")\n",
    "            # emotion, img, usage = data_df['emotion'][i], data_df['pixels'][i], data_df['Usage'][i]\n",
    "\n",
    "            val = img.split(\" \")\n",
    "\n",
    "            pixels = np.array(val, 'float32')\n",
    "\n",
    "            emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "\n",
    "            if 'Training' in usage:\n",
    "                y_train.append(emotion)\n",
    "                x_train.append(pixels)\n",
    "            elif 'PublicTest' in usage:\n",
    "                y_test.append(emotion)\n",
    "                x_test.append(pixels)\n",
    "        except:\n",
    "            print(\"\", end=\"\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # data transformation for train and test sets\n",
    "    x_train = np.array(x_train, 'float32')\n",
    "    y_train = np.array(y_train, 'float32')\n",
    "    x_test = np.array(x_test, 'float32')\n",
    "    y_test = np.array(y_test, 'float32')\n",
    "\n",
    "    x_train /= 255  # normalize inputs between [0, 1]\n",
    "    x_test /= 255\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    y_train = y_train.reshape(y_train.shape[0], 7)\n",
    "    y_train = y_train.astype('int16')\n",
    "    y_test = y_test.reshape(y_test.shape[0], 7)\n",
    "    y_test = y_test.astype('int16')\n",
    "\n",
    "    print('--------x_train.shape:', x_train.shape)\n",
    "    print('--------y_train.shape:', y_train.shape)\n",
    "\n",
    "\n",
    "    print(len(x_train), 'train x size')\n",
    "    print(len(y_train), 'train y size')\n",
    "    print(len(x_test), 'test x size')\n",
    "    print(len(y_test), 'test y size')\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def batch_process(path, batch_size):\n",
    "    x_train, y_train, x_test, y_test = reshape_dataset(path)\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, train_generator\n",
    "\n",
    "\n",
    "def compile_model(models):\n",
    "    model = models.compile(loss='categorical_crossentropy'\n",
    "                  , optimizer=keras.optimizers.Adam()\n",
    "                   , metrics=['accuracy']\n",
    "                   )\n",
    "    return model\n",
    "\n",
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "\n",
    "num_classes = 7  # angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "\n",
    "#batch_size = 128\n",
    "#num_classes = len(classes)\n",
    "#epochs =  10\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0, 'CPU': 56})  # max: 1 gpu, 56 cpu\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "path = 'fer2013.csv'\n",
    "x_train, y_train, x_test, y_test = reshape_dataset(path, num_classes)\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # for data_batch, label_batch in train_generator:\n",
    "    #     print('data_batch:', data_batch.shape)\n",
    "    #     print('label_batch:', label_batch.shape)\n",
    "\n",
    "m = build_model(num_classes)\n",
    "print('model:', m)\n",
    "print('train_generator:', train_generator)\n",
    "# m = compile_model(m)\n",
    "m.compile(loss='categorical_crossentropy'\n",
    "               , optimizer=keras.optimizers.Adam()\n",
    "               , metrics=['accuracy']\n",
    "               )\n",
    "print('m:', m)\n",
    "m.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs)\n",
    "\n",
    "m.save('facial_expression_model_weights.h5')\n",
    "print('save weight..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from train import emotion_analysis, reshape_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "#from model import build_model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # path = '/home/jing/PycharmProjects/facial/dataset/fer2013/fer2013.csv'\n",
    "    num_classes = 7\n",
    "\n",
    "    # x_train, y_train, x_test, y_test = reshape_dataset(path, num_classes)\n",
    "\n",
    "    model = build_model(num_classes)\n",
    "    model.load_weights('facial_expression_model_weights.h5')\n",
    "\n",
    "    # monitor_testset_results = False\n",
    "    #\n",
    "    # if monitor_testset_results == True:\n",
    "    #     # make predictions for test set\n",
    "    #     predictions = model.predict(x_test)\n",
    "    #\n",
    "    #     index = 0\n",
    "    #     for i in predictions:\n",
    "    #         if index < 30 and index >= 20:\n",
    "    #             # print(i) #predicted scores\n",
    "    #             # print(y_test[index]) #actual scores\n",
    "    #\n",
    "    #             testing_img = np.array(x_test[index], 'float32')\n",
    "    #             testing_img = testing_img.reshape([48, 48])\n",
    "    #\n",
    "    #             plt.gray()\n",
    "    #             plt.imshow(testing_img)\n",
    "    #             plt.show()\n",
    "    #\n",
    "    #             print(i)\n",
    "    #\n",
    "    #             emotion_analysis(i)\n",
    "    #             print(\"----------------------------------------------\")\n",
    "    #         index = index + 1\n",
    "\n",
    "    # ------------------------------\n",
    "    # make prediction for custom image out of test set\n",
    "\n",
    "    # img = image.load_img(\"/home/jing/PycharmProjects/facial/dataset/pablo.png\", grayscale=True, target_size=(48, 48))\n",
    "    # img = image.load_img(\"/home/jing/PycharmProjects/facial/dataset/monalisa.png\", grayscale=True, target_size=(48, 48))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"xindi.jpg\", grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "t1 = emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48])\n",
    "plt.gray()\n",
    "\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\",\"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
